#!/bin/bash
# this script is part of https://github.com/WolfgangFahl/ProceedingsTitleParser
# it gets the test data sets for
#
# 1. CEUR-WS
#
# WF 2020-07-01

sampledir="sampledata"

#
# download
#
download() {
  local l_src="$1"
  local l_target="$2"
  if [ ! -f $l_target ]
  then
    echo "downloading $l_target from $l_src"
    curl -o $l_target $l_src
  else
    echo "$l_target already downloaded"
  fi
  wc -l $l_target
}

#
# get the data from CEUR-WS
#
getCEURWS() {
  echo "getting sample data for CEUR-WS"
  samplehtml=$sampledir/ceurs-ws.html
  sampletxt=$sampledir/proceedings-ceur-ws.txt
  download http://ceur-ws.org/ $samplehtml
  if [ ! -f $sampletxt ]
  then
    echo "filtering proceeding titles from $samplehtml into $sampletxt"
    cat $samplehtml  | python3 -c 'import html, sys; [print(html.unescape(l), end="") for l in sys.stdin]' | gawk '
BEGIN {
 ignorelines=1
}
/MAINTABLE/ { ignorelines=0; next }
ignorelines { next }
# ignore
# get Vol from e.g.
# <a href="http://ceur-ws.org/Vol-2632/">MIning and REasoning with Legal texts.</a>
/ONLINE:.*<[Aa]\s+(HREF|href)=".*">.*<\/[aA]>/ {
  found=match($0,/[#/]Vol-[0-9]{1,4}/)
  if (found) {
     vol=substr($0, RSTART+1, RLENGTH-1)
     printf("|id=%s\n",vol)
     if (vol=="Vol-1")
       ignorelines=1
  }
  next
}
/<[Aa]\s+(HREF|href)=".*">/,/<\/[aA]>/ { next }
/ftp\/pub/ { next }
/ARCHIVE:/ {next }
/Published on CEUR-WS:/ { next }
/<[aA]\sname/ { next }
/Edited by: / { next }
/<font>/ { next }
/<font size=.?-2.?>/ { next }
/<\/font>/ { next }
/<TD\salign="left"\sbgcolor="#DCDBD7">/ { next }
/#00000/ { next }
/#CCEBC7/ { next }
/#F0D2F5/ { next }
/<\/TD>/ { next }
/<\/td>/ { next }
/<[\/]?table|TABLE>/ { next }
/<[\/]?tr|TR>/ { next }
/--/ { print ""; next }
# FILTER raw html
{
  line=$0
  gsub("<BR>","",line)
  gsub("<br>","",line)
  gsub("<sup>2</sup>","2",line)
  gsub("<(td|TD).bgcolor=.#FFFFFF.>","",line)
  # nbsp
  gsub("Â </TD>","",line)
  printf ("%s",line)
}' | sed  '/^$/d'  > $sampletxt
 else
    echo "$sampletxt already filtered from $samplehtml"
 fi
 wc -l $sampletxt
}

#
# get the text files
#
getText() {
  for source in dblp wikidata
  do
     target=proceedings-$source.txt
     download http://wiki.bitplan.com/images/$target $sampledir/$target
  done
}

if [ ! -d $sampledir ]
then
  echo  "creating $sampledir directory"
  mkdir -p $sampledir
else
  echo "$sampledir directory already exists"
fi
getCEURWS
getText
